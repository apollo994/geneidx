{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95036f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb683502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to Predict Sites: Lenght, Offset, Cutoff and order (Markov chain)\n",
    "Start_profile\n",
    "6 3 -5 0\n",
    "# These are the start transition probabilities\n",
    "1 A 0.225005\n",
    "1 C -0.0848766\n",
    "1 G 0.149307\n",
    "1 T -0.495084\n",
    "2 A 0.179827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NO_SCORE\n",
    "number_of_isochores\n",
    "boundaries_of_isochore\n",
    "Absolute_cutoff_exons\n",
    "Coding_cutoff_oligos\n",
    "Site_factor\n",
    "Exon_factor\n",
    "HSP_factor\n",
    "Exon_weights\n",
    "Start_profile\n",
    "Acceptor_profile\n",
    "Donor_profile\n",
    "Stop_profile\n",
    "Markov_order\n",
    "Markov_Initial_probability_matrix\n",
    "Markov_Transition_probability_matrix\n",
    "maximum_number_of_donors_per_acceptor_site\n",
    "General_gene_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_position = 4 ** (order + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_list = [\"109871\", \"12968\", \"132113\", \"13684\", \"15368\", \"162425\", \"2769\", \"29760\", \"30195\", \"31276\", \"34765\", \"3656\", \"3702\", \"370843\", \"38033\", \"3885\", \"40658\", \"4069\", \"4081\", \"4113\", \"44689\", \"4530\", \"4565\", \"4641\", \"4787\", \"4897\", \"5037\", \"506608\", \"5141\", \"5180\", \"5207\", \"5297\", \"5346\", \"5501\", \"5507\", \"561515\", \"5691\", \"5807\", \"5833\", \"5855\", \"5888\", \"5911\", \"609292\", \"610380\", \"6182\", \"6239\", \"64495\", \"7029\", \"7175\", \"7209\", \"7227\", \"7425\", \"7460\", \"7462\", \"7463\", \"7719\", \"82660\", \"85445\", \"857276\", \"91402\", \"91411\", \"91432\", \"9606\", \"99883\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d615a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce811073",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = \"../docker/python-modules/Parameter_files.taxid/Ciona_intestinalis.7719.param\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = eval(\"\"\"[ \"absolute_cutoff_exons\":-15,    \"coding_cutoff_oligos\":-15,\n",
    "    \"no_score\" : -0.40,\n",
    "    \"site_factor\" : 1.51483,\n",
    "    \"exon_factor\" : 1.37056,\n",
    "    \"hsp_factor\"  : 0.19,\n",
    "    \"exon_weight\" : -12 ]\"\"\".replace(\"[\", \"{\").replace(\"]\", \"}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ece29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = eval(\"\"\"[ \"absolute_cutoff_exons\":-15,    \"coding_cutoff_oligos\":-15,\n",
    "    \"hsp_factor\"  : 0.19,\n",
    "    \"exon_weight\" : -12 ]\"\"\".replace(\"[\", \"{\").replace(\"]\", \"}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99816641",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52957b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dd).replace(\"{\", \"[\").replace(\"}\", \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all = set(['absolute_cutoff_exons', 'coding_cutoff_oligos', 'no_score',\n",
    "                'site_factor', 'exon_factor', 'hsp_factor', 'exon_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list_all - set(list(dd.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b06cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all = set(['absolute_cutoff_exons', 'coding_cutoff_oligos', 'no_score',\n",
    "                'site_factor', 'exon_factor', 'hsp_factor', 'exon_weight'])\n",
    "\n",
    "dict_all_params = eval(\"\"\"[ \"absolute_cutoff_exons\":-15,    \"coding_cutoff_oligos\":-15,\n",
    "                        \"exon_weight\" : -12 ]\"\"\".replace(\"[\", \"{\").replace(\"]\", \"}\"))\n",
    "#dict_all_params = eval(\"\"\"[ \"absolute_cutoff_exons\":-15,    \"coding_cutoff_oligos\":-15,\n",
    "#                        \"hsp_factor\"  : 0.19,\n",
    "#                        \"exon_weight\" : -12 ]\"\"\".replace(\"[\", \"{\").replace(\"]\", \"}\"))\n",
    "\n",
    "def find_missing_param(list_defined, param_file):\n",
    "    \n",
    "    params_to_search = list(list_all - set(list(list_defined)))\n",
    "    \n",
    "    for text_to_find in params_to_search:\n",
    "        \n",
    "        started = 0\n",
    "\n",
    "        with open(param_file) as f:\n",
    "            for line in f:\n",
    "                if started == 0:\n",
    "                    if line.strip().lower() == text_to_find:\n",
    "                        param_name = line.strip().lower()\n",
    "                        print(line.strip())\n",
    "                        started = -1\n",
    "\n",
    "                # we have just found the label of the parameter of interest\n",
    "                # here we need read the value\n",
    "                elif started == -1:\n",
    "                    vals = line.strip().split(' ')\n",
    "                    \n",
    "                    # we check whether there are multiple values,\n",
    "                    # if so, we take the value of the last one\n",
    "                    if vals.count(vals[0]) > vals.count(vals[-1]):\n",
    "                        dict_all_params[param_name] = vals[0]\n",
    "                        print(vals[0])\n",
    "                        \n",
    "                    else:\n",
    "                        dict_all_params[param_name] = vals[-1]\n",
    "                        print(vals[-1])\n",
    "        \n",
    "                    started = 0\n",
    "            \n",
    "                    break\n",
    "    return str(dict_all_params).replace(\"{\", \"[\").replace(\"}\", \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181e0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO_SCORE\n",
      "0\n",
      "Exon_factor\n",
      "0.35\n",
      "HSP_factor\n",
      "1.0\n",
      "Site_factor\n",
      "0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['absolute_cutoff_exons': -15, 'coding_cutoff_oligos': -15, 'exon_weight': -12, 'no_score': '0', 'exon_factor': '0.35', 'hsp_factor': '1.0', 'site_factor': '0.65']\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_param(dict_all_params.keys(), file_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "started = 0\n",
    "\n",
    "files_created = []\n",
    "\n",
    "text_to_find = \"exon_factor\"\n",
    "taxid = 35523\n",
    "\n",
    "for text_to_find in dd.keys():\n",
    "    # removing the new line characters\n",
    "    # with open(f'../docker/python-modules/Parameter_files.taxid/{taxid}.param') as f:\n",
    "    with open(file_to_read) as f:\n",
    "        for line in f:\n",
    "    #        print(line)\n",
    "            if started == 0:\n",
    "                if line.strip().lower() == text_to_find:\n",
    "                    print(line.strip())\n",
    "                    started = -1\n",
    "\n",
    "            # we have just found the label of the profile of interest\n",
    "            # here we need read the value\n",
    "            elif started == -1:\n",
    "                vals = line.strip().split(' ')\n",
    "                if vals.count(vals[0]) > vals.count(vals[-1]):\n",
    "                    print(vals[0])\n",
    "                else:\n",
    "                    print(vals[-1])\n",
    "    #             print(line)\n",
    "                started = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "started = 0\n",
    "\n",
    "files_created = []\n",
    "\n",
    "pattern = r'([a-zA-Z]+_[fF]actor)'\n",
    "taxid = 35523\n",
    "\n",
    "# removing the new line characters\n",
    "# with open(f'../docker/python-modules/Parameter_files.taxid/{taxid}.param') as f:\n",
    "with open(file_to_read) as f:\n",
    "    for line in f:\n",
    "#        print(line)\n",
    "        if started == 0:\n",
    "            matches = re.match(pattern, line, flags=re.IGNORECASE)\n",
    "\n",
    "            # if there is any match, get the groups and start a new file\n",
    "            if matches is not None:                \n",
    "                groups = matches.groups()\n",
    "                print(line.strip(), end = '')\n",
    "                started = -1\n",
    "\n",
    "        # we have just found the label of the profile of interest\n",
    "        # here we need read the value\n",
    "        elif started == -1:\n",
    "            vals = line.split(' ')\n",
    "            if vals.count(vals[0]) > vals.count(vals[-1]):\n",
    "                print(vals[0], end = \"\")\n",
    "            else:\n",
    "                print(vals[-1], end = \"\")\n",
    "#             print(line)\n",
    "            started = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a765ba4",
   "metadata": {},
   "source": [
    "# Site profiles\n",
    "Start_profile\n",
    "\n",
    "Acceptor_profile\n",
    "\n",
    "Donor_profile\n",
    "\n",
    "Stop_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'([a-zA-Z]+)_[Pp]rofile'\n",
    "\n",
    "def taxid_to_splitted_files(taxid):\n",
    "    started = 0\n",
    "\n",
    "    files_created = []\n",
    "    \n",
    "    # removing the new line characters\n",
    "    with open(f'../docker/python-modules/Parameter_files.taxid/{taxid}.param') as f:\n",
    "        for line in f:\n",
    "    #        print(line)\n",
    "            if started == 0:\n",
    "                matches = re.match(pattern, line)\n",
    "\n",
    "                # if there is any match, get the groups and start a new file\n",
    "                if matches is not None:                \n",
    "                    groups = matches.groups()\n",
    "                    # print(line, end = '')\n",
    "\n",
    "                    # create the file that will contain the given profile\n",
    "                    # only if it has not been created before\n",
    "                    filename = groups[0].lower() + \"_profile.{}.param\".format(taxid)\n",
    "                    if filename not in files_created:\n",
    "                        files_created.append(filename)\n",
    "                        started = -1\n",
    "\n",
    "                        print(\"Saving\", filename)\n",
    "#                         fW = open(filename, \"w\")\n",
    "#                         fW.write(line)\n",
    "\n",
    "            # we have just found the label of the profile of interest\n",
    "            # here we need to know the length and order\n",
    "            elif started == -1:\n",
    "                # write line to file\n",
    "#                 fW.write(line)\n",
    "\n",
    "                # process the content of this line\n",
    "                clean_line = line.strip()\n",
    "                splitted_line = clean_line.split(\" \")\n",
    "                length_pwm = int(splitted_line[0])\n",
    "                order_pwm = int(splitted_line[3])\n",
    "\n",
    "                rep_position = 4 ** (order_pwm + 1)\n",
    "                total_to_read = rep_position * length_pwm\n",
    "\n",
    "                # define started as the total number of lines to be read and written to the output file\n",
    "                started = total_to_read + 1\n",
    "\n",
    "            # these are the lines that we are reading and adding to the output file of the profile\n",
    "            elif started > 1:\n",
    "                # write line to file and substract one\n",
    "#                 fW.write(line)\n",
    "                started -= 1\n",
    "                # print(line, end = '')\n",
    "\n",
    "            # this is the last line to be added, so we add it and close the file\n",
    "            elif started == 1:\n",
    "                # write line to file and substract one\n",
    "#                 fW.write(line)\n",
    "                started -= 1\n",
    "                # print(line, end = '')\n",
    "\n",
    "                # close the file as we finished adding that profile\n",
    "#                 fW.close()\n",
    "                \n",
    "                \n",
    "    return \"{} splitted into {}\".format(taxid, files_created)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff911d",
   "metadata": {},
   "source": [
    "# Factors\n",
    "\n",
    "Site_factor\n",
    "\n",
    "Exon_factor\n",
    "\n",
    "HSP_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5205d4",
   "metadata": {},
   "source": [
    "# Autocomputed matrices\n",
    "\n",
    "Markov_order\n",
    "\n",
    "Markov_Initial_probability_matrix\n",
    "\n",
    "Markov_Transition_probability_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88dc1d",
   "metadata": {},
   "source": [
    "# Exon weights\n",
    "\n",
    "Exon_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f5d48",
   "metadata": {},
   "source": [
    "# Isochores & donors per acceptor\n",
    "I would fix this to always a single isochore and 5 donors per acceptor\n",
    "\n",
    "number_of_isochores\n",
    "\n",
    "boundaries_of_isochore\n",
    "\n",
    "maximum_number_of_donors_per_acceptor_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec785a9",
   "metadata": {},
   "source": [
    "# Non-homology penalty\n",
    "\n",
    "In general it is defined to 0 as all Geneid parameter files are not used with evidence. We should test and define this value based on something. Initially I would set it to -0.10.\n",
    "\n",
    "NO_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472361a8",
   "metadata": {},
   "source": [
    "# Cutoffs\n",
    "\n",
    "Absolute_cutoff_exons\n",
    "\n",
    "Coding_cutoff_oligos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c79a0a",
   "metadata": {},
   "source": [
    "# General gene model (GenAmic)\n",
    "\n",
    "General_gene_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e26a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_to_splitted_files(\"Ciona_intestinalis.7719\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2dcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a43cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358b609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433399ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in taxid_list:\n",
    "    print(taxid_to_splitted_files(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bc704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
