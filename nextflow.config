/*
* This configuration file is main one. This includes the pipeline parameters
* and different config files, one for each profile.
* You can switch among them using the Nextflow parameter -profile <<PROFILENAME>>
*/

// include the pipeline parameters from this file
includeConfig "$projectDir/params.config"

// include the base configuration
includeConfig 'conf/base.config'


process {
    // indicates the default container to be used if not defined within the modules
    // container = 'ferriolcalvet/geneid-fetching:latest'

    withLabel: geneidx {
        container = "emiliorighi/geneidx:latest"
    }

    withLabel: samtools {
        container = "quay.io/biocontainers/samtools:1.15--h1170115_1"
    }

    withLabel: diamond {
        container = "quay.io/biocontainers/diamond:0.9.30--h56fc30b_0"
        cpus   = { check_max( 4     * task.attempt, 'cpus'    ) }
        memory = { check_max( 40.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 8.h   * task.attempt, 'time'    ) }
    }
    // custom container options in case you use docker for mapping the users and avoid docker writing files as root
    containerOptions = { workflow.containerEngine == "docker" ? '-u $(id -u):$(id -g)': null}

    // ***********
    // NOT SURE ABOUT THE IMPACT OF THIS CHANGE
    // personalize shell execution, done for avoiding errors in grep
    // ***********
    shell = ['/bin/bash','-u']



}

// indicates where to write the singularity images if you choose to use this container
singularity.cacheDir = "./singularity"

// this should help in removing the "work" directory after the processes have finished successfully
cleanup = true





// define different profiles
profiles {
    standard {
   	    includeConfig 'conf/standard.config'
    }
    hpc_sge {
        includeConfig 'conf/sge.config'
    }
    hpc_slurm {
        includeConfig 'conf/slurm.config'
    }
    cloud {
        includeConfig 'conf/awsbatch.config'
    }
    retry {
        includeConfig 'conf/retry_example.config'
    }


    docker {
      docker.enabled         = true
      docker.userEmulation   = true
      singularity.enabled    = false
      podman.enabled         = false
      shifter.enabled        = false
      charliecloud.enabled   = false
    }
    singularity {
      singularity.enabled    = true
      singularity.autoMounts = true
      docker.enabled         = false
      podman.enabled         = false
      shifter.enabled        = false
      charliecloud.enabled   = false
    }



}






// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
